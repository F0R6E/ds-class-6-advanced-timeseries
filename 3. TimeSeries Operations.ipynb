{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries Operations\n",
    "\n",
    "In this lesson we'll explore time shifting and resampling (grouping). Two of the most common operations with Time Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(10) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=10, freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    501.234286\n",
       "2018-01-02    493.716639\n",
       "2018-01-03    504.774312\n",
       "2018-01-04    507.286344\n",
       "2018-01-05    484.088206\n",
       "2018-01-06    503.133241\n",
       "2018-01-07    497.514691\n",
       "2018-01-08    491.456866\n",
       "2018-01-09    504.404706\n",
       "2018-01-10    510.683477\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01           NaN\n",
       "2018-01-02    501.234286\n",
       "2018-01-03    493.716639\n",
       "2018-01-04    504.774312\n",
       "2018-01-05    507.286344\n",
       "2018-01-06    484.088206\n",
       "2018-01-07    503.133241\n",
       "2018-01-08    497.514691\n",
       "2018-01-09    491.456866\n",
       "2018-01-10    504.404706\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Shfit (1)</th>\n",
       "      <th>Shift (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>501.234286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>493.716639</td>\n",
       "      <td>501.234286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>504.774312</td>\n",
       "      <td>493.716639</td>\n",
       "      <td>501.234286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>507.286344</td>\n",
       "      <td>504.774312</td>\n",
       "      <td>493.716639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>484.088206</td>\n",
       "      <td>507.286344</td>\n",
       "      <td>504.774312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>503.133241</td>\n",
       "      <td>484.088206</td>\n",
       "      <td>507.286344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>497.514691</td>\n",
       "      <td>503.133241</td>\n",
       "      <td>484.088206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>491.456866</td>\n",
       "      <td>497.514691</td>\n",
       "      <td>503.133241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>504.404706</td>\n",
       "      <td>491.456866</td>\n",
       "      <td>497.514691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>510.683477</td>\n",
       "      <td>504.404706</td>\n",
       "      <td>491.456866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original   Shfit (1)   Shift (2)\n",
       "2018-01-01  501.234286         NaN         NaN\n",
       "2018-01-02  493.716639  501.234286         NaN\n",
       "2018-01-03  504.774312  493.716639  501.234286\n",
       "2018-01-04  507.286344  504.774312  493.716639\n",
       "2018-01-05  484.088206  507.286344  504.774312\n",
       "2018-01-06  503.133241  484.088206  507.286344\n",
       "2018-01-07  497.514691  503.133241  484.088206\n",
       "2018-01-08  491.456866  497.514691  503.133241\n",
       "2018-01-09  504.404706  491.456866  497.514691\n",
       "2018-01-10  510.683477  504.404706  491.456866"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Original': ts,\n",
    "    'Shfit (1)': ts.shift(1),\n",
    "    'Shift (2)': ts.shift(2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations are usually employed to compare the timeseries with previous values of the same time series. For example, calculating the percent change over the previous period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>501.234286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>493.716639</td>\n",
       "      <td>501.234286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>504.774312</td>\n",
       "      <td>493.716639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>507.286344</td>\n",
       "      <td>504.774312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>484.088206</td>\n",
       "      <td>507.286344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>503.133241</td>\n",
       "      <td>484.088206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>497.514691</td>\n",
       "      <td>503.133241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>491.456866</td>\n",
       "      <td>497.514691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>504.404706</td>\n",
       "      <td>491.456866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>510.683477</td>\n",
       "      <td>504.404706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original     Shifted\n",
       "2018-01-01  501.234286         NaN\n",
       "2018-01-02  493.716639  501.234286\n",
       "2018-01-03  504.774312  493.716639\n",
       "2018-01-04  507.286344  504.774312\n",
       "2018-01-05  484.088206  507.286344\n",
       "2018-01-06  503.133241  484.088206\n",
       "2018-01-07  497.514691  503.133241\n",
       "2018-01-08  491.456866  497.514691\n",
       "2018-01-09  504.404706  491.456866\n",
       "2018-01-10  510.683477  504.404706"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Original': ts,\n",
    "    'Shifted': ts.shift(1)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01         NaN\n",
       "2018-01-02   -0.014998\n",
       "2018-01-03    0.022397\n",
       "2018-01-04    0.004977\n",
       "2018-01-05   -0.045730\n",
       "2018-01-06    0.039342\n",
       "2018-01-07   -0.011167\n",
       "2018-01-08   -0.012176\n",
       "2018-01-09    0.026346\n",
       "2018-01-10    0.012448\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Original'] / df['Shifted']) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how much sales grew or shrank vs the previous month.\n",
    "\n",
    "This is a particularly silly example, because there's a pandas method specially intended for percentage changes: [`pct_change()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pct_change.html), so we don't even need `shift`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01         NaN\n",
       "2018-01-02   -0.014998\n",
       "2018-01-03    0.022397\n",
       "2018-01-04    0.004977\n",
       "2018-01-05   -0.045730\n",
       "2018-01-06    0.039342\n",
       "2018-01-07   -0.011167\n",
       "2018-01-08   -0.012176\n",
       "2018-01-09    0.026346\n",
       "2018-01-10    0.012448\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting also works with smaller periods, just changing the time of the original timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:15:00    501.234286\n",
       "2018-01-02 00:15:00    493.716639\n",
       "2018-01-03 00:15:00    504.774312\n",
       "2018-01-04 00:15:00    507.286344\n",
       "2018-01-05 00:15:00    484.088206\n",
       "2018-01-06 00:15:00    503.133241\n",
       "2018-01-07 00:15:00    497.514691\n",
       "2018-01-08 00:15:00    491.456866\n",
       "2018-01-09 00:15:00    504.404706\n",
       "2018-01-10 00:15:00    510.683477\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1, freq='15Min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Frequency\n",
    "\n",
    "We'll now see how to change the frequency of our indexes. These will be just raw adjustments we'll do to directly modify the frequency of our data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.923528\n",
       "2018-01-01 01:00:00    500.470628\n",
       "2018-01-01 02:00:00    506.498649\n",
       "2018-01-01 03:00:00    493.943460\n",
       "2018-01-01 04:00:00    505.499514\n",
       "2018-01-01 05:00:00    498.041784\n",
       "2018-01-01 06:00:00    496.484607\n",
       "2018-01-01 07:00:00    489.843080\n",
       "2018-01-01 08:00:00    484.456180\n",
       "2018-01-01 09:00:00    506.811008\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(10) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=10, freq='H'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.923528\n",
       "2018-01-01 00:45:00           NaN\n",
       "2018-01-01 01:30:00           NaN\n",
       "2018-01-01 02:15:00           NaN\n",
       "2018-01-01 03:00:00    493.943460\n",
       "2018-01-01 03:45:00           NaN\n",
       "2018-01-01 04:30:00           NaN\n",
       "2018-01-01 05:15:00           NaN\n",
       "2018-01-01 06:00:00    496.484607\n",
       "2018-01-01 06:45:00           NaN\n",
       "2018-01-01 07:30:00           NaN\n",
       "2018-01-01 08:15:00           NaN\n",
       "2018-01-01 09:00:00    506.811008\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.923528\n",
       "2018-01-01 00:45:00    495.923528\n",
       "2018-01-01 01:30:00    500.470628\n",
       "2018-01-01 02:15:00    506.498649\n",
       "2018-01-01 03:00:00    493.943460\n",
       "2018-01-01 03:45:00    493.943460\n",
       "2018-01-01 04:30:00    505.499514\n",
       "2018-01-01 05:15:00    498.041784\n",
       "2018-01-01 06:00:00    496.484607\n",
       "2018-01-01 06:45:00    496.484607\n",
       "2018-01-01 07:30:00    489.843080\n",
       "2018-01-01 08:15:00    484.456180\n",
       "2018-01-01 09:00:00    506.811008\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45Min', method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.923528\n",
       "2018-01-01 00:45:00    500.470628\n",
       "2018-01-01 01:30:00    506.498649\n",
       "2018-01-01 02:15:00    493.943460\n",
       "2018-01-01 03:00:00    493.943460\n",
       "2018-01-01 03:45:00    505.499514\n",
       "2018-01-01 04:30:00    498.041784\n",
       "2018-01-01 05:15:00    496.484607\n",
       "2018-01-01 06:00:00    496.484607\n",
       "2018-01-01 06:45:00    489.843080\n",
       "2018-01-01 07:30:00    484.456180\n",
       "2018-01-01 08:15:00    506.811008\n",
       "2018-01-01 09:00:00    506.811008\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45Min', method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.asfreq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these examples, we've gone from a \"less frequent\" index to a \"more frequent\" index. But we could go the other way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.781759\n",
       "2018-01-01 00:30:00    484.041645\n",
       "2018-01-01 01:00:00    507.895081\n",
       "2018-01-01 01:30:00    487.605316\n",
       "2018-01-01 02:00:00    508.826438\n",
       "2018-01-01 02:30:00    504.814993\n",
       "2018-01-01 03:00:00    491.729141\n",
       "2018-01-01 03:30:00    496.421283\n",
       "2018-01-01 04:00:00    510.332442\n",
       "2018-01-01 04:30:00    496.612527\n",
       "2018-01-01 05:00:00    485.377065\n",
       "2018-01-01 05:30:00    504.601887\n",
       "2018-01-01 06:00:00    490.598199\n",
       "2018-01-01 06:30:00    514.362441\n",
       "2018-01-01 07:00:00    493.276122\n",
       "2018-01-01 07:30:00    504.709501\n",
       "2018-01-01 08:00:00    475.797679\n",
       "2018-01-01 08:30:00    500.485632\n",
       "2018-01-01 09:00:00    504.972745\n",
       "2018-01-01 09:30:00    500.370554\n",
       "Freq: 30T, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(20) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=20, freq='30min'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.781759\n",
       "2018-01-01 02:00:00    508.826438\n",
       "2018-01-01 04:00:00    510.332442\n",
       "2018-01-01 06:00:00    490.598199\n",
       "2018-01-01 08:00:00    475.797679\n",
       "Freq: 2H, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.781759\n",
       "2018-01-01 02:25:00           NaN\n",
       "2018-01-01 04:50:00           NaN\n",
       "2018-01-01 07:15:00           NaN\n",
       "Freq: 145T, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H25min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    495.781759\n",
       "2018-01-01 02:25:00    508.826438\n",
       "2018-01-01 04:50:00    496.612527\n",
       "2018-01-01 07:15:00    493.276122\n",
       "Freq: 145T, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H25min', method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if you want to do some more \"advanced\" filling. For example, filling the new freq values with the \"mean\"? For that, we'll use resampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Resampling a timeseries is converting it to another time frequency. If you're going from high frequency to low frequency, the process is called \"downsampling\", and it involves an aggregation process. For example, you have daily sales data, and you want to aggregate it by month. You'll be \"grouping\" your daily sales per month, and you need to decide the aggregation operation to perform. For example, `sum` to get the total sales per month, or `mean` to get the average sale. Let's use an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-16    498.767961\n",
       "2018-01-18    499.898482\n",
       "2018-02-02    510.747610\n",
       "2018-02-27    493.487023\n",
       "2018-03-22    488.410878\n",
       "2018-04-20    494.345752\n",
       "2018-04-26    506.777721\n",
       "2018-05-04    505.595108\n",
       "2018-05-12    515.096785\n",
       "2018-06-30    513.510190\n",
       "2018-08-05    532.511595\n",
       "2018-08-28    490.414338\n",
       "2018-09-26    494.161538\n",
       "2018-10-05    505.716774\n",
       "2018-10-10    483.577099\n",
       "2018-12-12    492.315935\n",
       "2018-12-23    514.084808\n",
       "2018-12-25    498.880580\n",
       "2018-12-28    518.482966\n",
       "2018-12-31    490.358918\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_days_2018 = pd.date_range(start='2018-01-01', end='2018-12-31', freq='D')\n",
    "ts = pd.Series(\n",
    "    np.random.randn(20) * 10 + 500,\n",
    "    index=np.random.choice(all_days_2018, size=20))\n",
    "\n",
    "ts.sort_index(inplace=True)\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "January sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-16    498.767961\n",
       "2018-01-18    499.898482\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998.6664427720889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-01'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "February sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-02-02    510.747610\n",
       "2018-02-27    493.487023\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004.2346331586655"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-02'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling**: We'll now use `resample` to \"group\" the sales monthly (downsampling our TimeSeries), and calculate the total sales per month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-31     998.666443\n",
       "2018-02-28    1004.234633\n",
       "2018-03-31     488.410878\n",
       "2018-04-30    1001.123473\n",
       "2018-05-31    1020.691892\n",
       "2018-06-30     513.510190\n",
       "2018-07-31       0.000000\n",
       "2018-08-31    1022.925933\n",
       "2018-09-30     494.161538\n",
       "2018-10-31     989.293873\n",
       "2018-11-30       0.000000\n",
       "2018-12-31    2514.123207\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('M').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `M` means \"month end frequency. We could instead choose \"Month Start\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01     998.666443\n",
       "2018-02-01    1004.234633\n",
       "2018-03-01     488.410878\n",
       "2018-04-01    1001.123473\n",
       "2018-05-01    1020.691892\n",
       "2018-06-01     513.510190\n",
       "2018-07-01       0.000000\n",
       "2018-08-01    1022.925933\n",
       "2018-09-01     494.161538\n",
       "2018-10-01     989.293873\n",
       "2018-11-01       0.000000\n",
       "2018-12-01    2514.123207\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('MS').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which would of course yield the same results, but the index contains the first day of each month. More correctly speaking, in this example, we're collecting sales of _\"the period January 2018\"_. Pandas also has a `Period` type, which we can use with the `kind` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01     998.666443\n",
       "2018-02    1004.234633\n",
       "2018-03     488.410878\n",
       "2018-04    1001.123473\n",
       "2018-05    1020.691892\n",
       "2018-06     513.510190\n",
       "2018-07       0.000000\n",
       "2018-08    1022.925933\n",
       "2018-09     494.161538\n",
       "2018-10     989.293873\n",
       "2018-11       0.000000\n",
       "2018-12    2514.123207\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales = ts.resample('M', kind='period').sum()\n",
    "monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
       "             '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12'],\n",
       "            dtype='period[M]', freq='M')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Index is a `PeriodIndex`. Each entry in the index is of type `pd.Period`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-01', 'M')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period support basic arithmetic operations which makes them convenient to express these time ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-06', 'M')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2018-01') + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-01-01 09:00', 'H')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2018-01', freq='H') + 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsampling**: With upsampling we'll convert a low-frequency time series to a higher frequency time series. We'll add more \"time points\". Let's use an example:\n",
    "\n",
    "We'll start with 3 months of sales, only 3 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    492.025978\n",
       "2018-02-01    498.184135\n",
       "2018-03-01    492.677314\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(3) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=3, freq='MS'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now `resample` it to be \"Semi Month\", every 15 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    492.025978\n",
       "2018-01-15           NaN\n",
       "2018-02-01    498.184135\n",
       "2018-02-15           NaN\n",
       "2018-03-01    492.677314\n",
       "Freq: SMS-15, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('SMS').asfreq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see, we have a few missing values, because we don't have data for those specific time periods. What can you do with that missing data? One option is to fill it with previous data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    492.025978\n",
       "2018-01-15    492.025978\n",
       "2018-02-01    498.184135\n",
       "2018-02-15    498.184135\n",
       "2018-03-01    492.677314\n",
       "Freq: SMS-15, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('SMS').ffill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
